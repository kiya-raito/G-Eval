{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMbDJDtC17pttpnb46EFEBr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#このノートブックについて\n","このノートブックでは，Ollama と deepeval を使用して，大規模言語モデル (LLM) の評価を行います．Ollamaは，ローカル環境でLLMを実行するためのツールであり，deepevalは，LLMの評価のためのPythonライブラリです．\n","\n","**\"評価メトリックを定義する\"**のcriteriaを変更することで，LLMの評価基準を変更することが出来ます．\\\n","また，**\"評価を実行して，tsvファイルに出力する．\"**の*input, actual_output, expected_output* で入出力や教師文を設定することが出来ます．\n","\n","---\n","このノートブックでは，以下の手順でLLMの評価を行います．\n","\n","1. Google Driveをマウントする\n","2. 必要なライブラリをインストールする\n","3. Ollamaをインストールする\n","4. CUDAドライバーをインストールする\n","5. 環境変数を設定する\n","6. Ollamaサーバーをバックグラウンドで起動する\n","7. llama3.2モデルをダウンロードする\n","8. OllamaのPythonライブラリをインストールする\n","9. deepevalにローカルモデルを設定する\n","10. 評価メトリックを定義する\n","11. 評価を実行する\n","---\n","※私のデータセットで試したときは，T4で動きました（ハイメモリでなくても）．\\\n","※途中，「セッションを再起動しなさい」という警告が出る場合があります．再起動するのが無難ですが，おそらく無視（キャンセル）でも大丈夫なはずです．"],"metadata":{"id":"PyJMfCd07WlT"}},{"cell_type":"code","source":["#@title Google Driveをマウントする\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"id":"nbholqFouw44"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"QGIyq18mGNoY"},"outputs":[],"source":["#@title 必要なライブラリをインストールする\n","!pip install deepeval  # deepeval: LLMの評価のためのライブラリ\n","!pip install ngrok  # ngrok: ローカルサーバーを外部に公開するためのツール\n","!pip install pyngrok # pyngrok: ngrokをPythonから操作するためのライブラリ"]},{"cell_type":"code","source":["# Ollamaをインストールする\n","!curl https://ollama.ai/install.sh | sh\n","\n","# CUDAドライバーをインストールする\n","!echo 'debconf debconf/frontend select Noninteractive' | sudo debconf-set-selections\n","!sudo apt-get update && sudo apt-get install -y cuda-drivers\n","\n","# 環境変数を設定する\n","import os\n","os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})"],"metadata":{"id":"hu7N6QaRguom"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Ollamaサーバーをバックグラウンドで起動する\n","!nohup ollama serve &"],"metadata":{"id":"gYKyO8Te9u-j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title セッション終了時に，ollamaサーバを終了\n","import atexit\n","import os\n","\n","def stop_ollama_server():\n","  os.system(\"pkill ollama\")\n","\n","atexit.register(stop_ollama_server)"],"metadata":{"id":"CXpYLz438r6h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title llama3.2モデルをダウンロードする\n","# サーバーの起動を待つ\n","import time\n","time.sleep(10)\n","\n","# llama3.2モデルをダウンロードする\n","!ollama pull llama3.2"],"metadata":{"id":"qmfF3Y7mjEC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title OllamaのPythonライブラリをインストールする\n","!pip install ollama"],"metadata":{"id":"str4hwvRvDo1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title deepevalにローカルモデルを設定する\n","import ollama\n","!deepeval set-local-model --model-name=llama3.2 \\\n","    --base-url=\"http://localhost:11434/v1/\" \\\n","    --api-key=\"ollama\""],"metadata":{"id":"j9hOiWnEVYuz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title タイムアウト時間を設定\n","import signal\n","\n","class TimeoutException(Exception):\n","    pass\n","\n","def timeout_handler(signum, frame):\n","    raise TimeoutException(\"60秒タイムアウトしました\")\n","\n","# タイムアウト時間を設定 (秒)\n","timeout_duration = 60"],"metadata":{"id":"gDVuSook5Lxo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title 評価メトリックを定義する\n","from deepeval.metrics import GEval # deepevalからGEvalメトリックをインポートします．GEvalは，生成されたテキストの正確性を評価するためのメトリックです．\n","from deepeval.test_case import LLMTestCaseParams # deepevalからLLMTestCaseParamsをインポートします．LLMTestCaseParamsは，テストケースのパラメータを定義するためのクラスです．\n","'''\n","correctness_metric = GEval(\n","    name=\"ここでメトリックの名前を設定．評価にはおそらく直接的には影響しない．\",\n","    criteria=\"ここで評価基準を定義する\",\n","    evaluation_params=[評価に使用するパラメータを設定．このサンプルでは，入力，実際の出力，期待される出力を使用する．],\n","    model = \"llama3.2\"  # 使用するモデルを\"llama3\n","'''\n","\n","\n","correctness_metric = GEval(\n","    name=\"Correctness\",  # メトリックの名前を\"Correctness\"に設定します．\n","    criteria=\"Determine whether the actual output is factually correct based on the expected output.\",  #@param {type:\"string\"} メトリックの基準を設定します．この基準は，生成されたテキストが事実的に正しいかどうかを判断するために使用されます．\n","    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT, LLMTestCaseParams.EXPECTED_OUTPUT],  # 評価に使用するパラメータを設定します．ここでは，入力，実際の出力，期待される出力が使用されます．\n","    model = \"llama3.2\"  # 使用するモデルを\"llama3\n",")"],"metadata":{"id":"pFNqj0ghoa2-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title 評価を実行して，tsvファイルに出力する．\n","# 評価を実行する\n","import pandas as pd # pandasライブラリをインポートします．pandasは，データ分析に広く使用されるライブラリです．\n","from deepeval.test_case import LLMTestCase # deepevalライブラリからLLMTestCaseをインポートします．LLMTestCaseは，テストケースを表すクラスです．\n","from tqdm import tqdm  # tqdmをインポート\n","'''\n","    test_case = LLMTestCase(\n","        input=row['input_column'],  # 入力文 # テストケースを作成します．inputは，入力文をヘッダー名で指定します．\n","        actual_output=row['actual_output_column'],  # LLMの出力 # actual_outputは，LLMの実際の出力をヘッダー名で指定します．\n","        expected_output=row['expected_output_column']  # 正解 # expected_outputは，期待される出力をヘッダー名で指定します．\n","    )\n","\n","    例（イメージ）：\n","    test_case = LLMTestCase(\n","        input=\"The dog chased the cat up the tree, who ran up the tree?\",\n","        actual_output=\"It depends, some might consider the cat, while others might argue the dog.\",\n","        expected_output=\"The cat.\"\n","    )\n","'''\n","\n","\n","# 入力ファイルと出力ファイルのパス\n","input_file = 'your_input_file(tsv)_path' # 入力ファイルのパスを指定します．入力ファイルは，タブ区切り値（TSV）形式である必要があります．\n","output_file = 'your_output_file(tsv)_path' # 出力ファイルのパスを指定します．出力ファイルは，タブ区切り値（TSV）形式で保存されます．\n","\n","# TSVファイルを読み込み\n","data = pd.read_csv(input_file, sep='\\t', nrows=None)   # nrowsは読み込み行数の制限\n","\n","# スコアを計算して追加するためのリスト\n","scores = [] # スコアを格納するためのリストを初期化します．\n","reasons = [] # 理由を格納するためのリストを初期化します．\n","\n","\n","# 各行に対してスコアを計算\n","for _, row in tqdm(data.iterrows(), total=data.shape[0], desc=\"Evaluating\"):\n","    try:\n","        # タイムアウトハンドラを設定\n","        signal.signal(signal.SIGALRM, timeout_handler)\n","        signal.alarm(timeout_duration)  # アラームを設定\n","\n","        test_case = LLMTestCase(\n","            input=row['input_column'],  #@param  # テストケースを作成します．inputは，入力文をヘッダー名で指定します．\n","            actual_output=row['actual_output_column'],  #@param {type:\"string\"} # LLMの出力 # actual_outputは，LLMの実際の出力をヘッダー名で指定します．\n","            expected_output=row['expected_output_column']  #@param {type:\"string\"}  # 正解 # expected_outputは，期待される出力をヘッダー名で指定します．\n","        )\n","\n","        correctness_metric.measure(test_case)  # スコアを計算 # correctness_metricを使用して，テストケースのスコアを計算します．\n","        scores.append(correctness_metric.score)  # スコアをリストに追加 # 計算されたスコアをscoresリストに追加します．\n","        reasons.append(correctness_metric.reason)  # 理由をリストに追加 # スコアの理由をreasonsリストに追加します．\n","    except TimeoutException:\n","        print(f\"Timeout occurred for row {row.name}\")\n","        scores.append(None)  # タイムアウトが発生した場合，スコアをリストに追加\n","        reasons.append(None)  # タイムアウトが発生した場合，理由をリストに追加\n","    except Exception as e:\n","        if \"Connection\" in str(e):\n","            raise  # ConnectionErrorが発生したら実行を停止\n","        else:\n","            print(f\"Error evaluating row {row.name}: {e}\")\n","            correctness_scores.append(None)\n","            correctness_reasons.append(None)\n","\n","# データフレームにスコアと理由を追加\n","data['Score'] = scores # データフレームに\"Score\"列を追加し，scoresリストの値を設定します．\n","data['Reason'] = reasons # データフレームに\"Reason\"列を追加し，reasonsリストの値を設定します．\n","\n","# 修正後のデータフレームをTSVファイルとして出力\n","data.to_csv(output_file, sep='\\t', index=False) # データフレームをTSVファイルとして出力します．sep='\\t'は，タブ区切り値（TSV）形式でファイルを保存することを指定します．index=Falseは，インデックスを出力しないことを指定します．\n","\n","print(f\"Scores and reasons added. Output saved to {output_file}\") # 出力ファイルのパスを表示します．"],"metadata":{"id":"HRDVx-9eYcnr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title ランタイムの切断\n","from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"u15JzYQiJai6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@title tsvファイルを出力しない場合のコード\n","from deepeval.test_case import LLMTestCase\n","...\n","\n","test_case = LLMTestCase(\n","input = \"The dog chased the cat up the tree, who ran up the tree?\", # @param {\"type\":\"string\"}\n","    # actual_output=\"It depends, some might consider the cat, while others might argue the dog.\",\n","    actual_output=\"The cat .\",  #@param\n","    expected_output=\"The cat.\"  #@param\n",")\n","\n","correctness_metric.measure(test_case)\n","print(correctness_metric.score)\n","print(correctness_metric.reason)"],"metadata":{"id":"BFAavBRpId4P"},"execution_count":null,"outputs":[]}]}